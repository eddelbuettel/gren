
R version 3.2.5 (2016-04-14) -- "Very, Very Secure Dishes"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ##############################  preamble  #############################
> # simulations for grVBEM to assess variable selection                 #
> # version: 01                                                         #
> # author: Magnus M?nch                                                #
> # created: 11-07-2017                                                 #
> # last edited: 11-07-2017                                             #
> #######################################################################
> 
> ###############################  notes  ###############################
> #                                                                     #
> #######################################################################
> 
> ### paths
> path.code <- as.character(ifelse(Sys.info()[1]=="Darwin","/Users/magnusmunch/Documents/PhD/EBEN/code/" ,"~/EBEN/code/"))
> path.res <- as.character(ifelse(Sys.info()[1]=="Darwin","/Users/magnusmunch/Documents/PhD/EBEN/results/" ,"~/EBEN/results/"))
> path.data <- as.character(ifelse(Sys.info()[1]=="Darwin","/Users/magnusmunch/Documents/PhD/EBEN/data/" ,"~/EBEN/data/"))
> path.graph <- "/Users/magnusmunch/Documents/PhD/EBEN/graphs/"
> 
> ### libraries
> library(Rcpp)
> library(glmnet)
Loading required package: Matrix
Loading required package: foreach
Loaded glmnet 2.0-5

> library(penalized)
Loading required package: survival
Welcome to penalized. For extended examples, see vignette("penalized").
> library(GRridge)
Loading required package: Iso
Iso 0.0-17
Loading required package: GSEABase
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ‘BiocGenerics’

The following objects are masked from ‘package:parallel’:

    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
    clusterExport, clusterMap, parApply, parCapply, parLapply,
    parLapplyLB, parRapply, parSapply, parSapplyLB

The following object is masked from ‘package:penalized’:

    as.data.frame

The following object is masked from ‘package:Matrix’:

    as.vector

The following objects are masked from ‘package:stats’:

    IQR, mad, xtabs

The following objects are masked from ‘package:base’:

    anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
    do.call, duplicated, eval, evalq, Filter, Find, get, grep, grepl,
    intersect, is.unsorted, lapply, lengths, Map, mapply, match, mget,
    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,
    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,
    union, unique, unlist, unsplit

Loading required package: Biobase
Welcome to Bioconductor

    Vignettes contain introductory material; view with
    'browseVignettes()'. To cite Bioconductor, see
    'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: annotate
Loading required package: AnnotationDbi
Loading required package: stats4
Loading required package: IRanges
Loading required package: S4Vectors

Attaching package: ‘IRanges’

The following object is masked from ‘package:Matrix’:

    expand

Loading required package: XML
Loading required package: graph

Attaching package: ‘graph’

The following object is masked from ‘package:XML’:

    addNode


Attaching package: ‘GRridge’

The following object is masked from ‘package:glmnet’:

    auc

Warning messages:
1: replacing previous import ‘stats::xtabs’ by ‘BiocGenerics::xtabs’ when loading ‘GRridge’ 
2: replacing previous import ‘GSEABase::intersect’ by ‘BiocGenerics::intersect’ when loading ‘GRridge’ 
3: replacing previous import ‘stats::mad’ by ‘BiocGenerics::mad’ when loading ‘GRridge’ 
4: replacing previous import ‘GSEABase::setdiff’ by ‘BiocGenerics::setdiff’ when loading ‘GRridge’ 
5: replacing previous import ‘penalized::as.data.frame’ by ‘BiocGenerics::as.data.frame’ when loading ‘GRridge’ 
6: replacing previous import ‘stats::IQR’ by ‘BiocGenerics::IQR’ when loading ‘GRridge’ 
> library(mvtnorm)
> library(pROC)
Type 'citation("pROC")' for a citation.

Attaching package: ‘pROC’

The following objects are masked from ‘package:GRridge’:

    auc, roc

The following objects are masked from ‘package:IRanges’:

    cov, var

The following object is masked from ‘package:glmnet’:

    auc

The following objects are masked from ‘package:stats’:

    cov, smooth, var

> library(psych)

Attaching package: ‘psych’

The following object is masked from ‘package:IRanges’:

    reflect

> 
> ### functions
> # source grENVB functions
> source(paste(path.code, "grVBEM.R", sep=""))
> 
> # function to cross-validate elastic net
> cv.en <- function(x, y, intercept=intercept) {
+   fit.pen <- cv.pen(x, y, intercept=intercept)
+   fit.en <- glmnet(x, y, family="binomial", alpha=fit.pen$alpha[which.min(fit.pen$cvll)],
+                    lambda=fit.pen$lambda[which.min(fit.pen$cvll)])
+   return(fit.en)
+ }
> 
> # function to cross-validate lambda1 and lambda2 in enet with fixed number of selected vars
> cv.pensel <- function(x, y, intercept, nsel, type=c("ridge", "lasso", "enet")) {
+   p <- ncol(x)
+   n <- nrow(x)
+   if(type=="enet") {
+     seq.alpha <- seq(0.01, 0.99, length.out=50)
+   } else if(type=="lasso"){
+     seq.alpha <- 1
+   } else if(type=="ridge") {
+     seq.alpha <- 0
+     df.fit <- list(df=NA)
+   }
+   nlambda <- 100
+   seq.lam <- seq.df <- seq.cvll <- numeric(length(seq.alpha))
+   for(a in 1:length(seq.alpha)) {
+     # first find the correct lambda for every alpha
+     suppressWarnings(df.fit <- glmnet(x, y, family="binomial", alpha=seq.alpha[a], 
+                                       standardize=FALSE, dfmax=nsel, intercept=intercept))
+     if(type=="ridge") {
+       lambda <- NULL
+     } else {
+       lambda <- tail(df.fit$lambda[df.fit$df <= nsel], n=2L)
+     }
+     found <- any(df.fit$df==nsel)
+     lambdamax <- max(abs(t(x) %*% (y - mean(y)*(1 - mean(y)))))/(n*seq.alpha[a])
+     while(!found & type!="ridge") {
+       found <- any(df.fit$df==nsel)
+       if(!found) {
+         lambdamax <- ifelse(length(tail(df.fit$lambda[df.fit$df < nsel], n=1L))==0,
+                             lambdamax, 
+                             ifelse(!all(df.fit$df < nsel),
+                                    ifelse(df.fit$df[1] > nsel,
+                                           tail(df.fit$lambda[which(!(df.fit$df < nsel))], n=1L),
+                                           df.fit$lambda[which(!(df.fit$df < nsel))[1] - 1]),
+                                    tail(df.fit$lambda, n=1L)))
+                             # tail(df.fit$lambda[df.fit$df < nsel], n=1L))
+         lambdamin <- ifelse(length(df.fit$lambda[df.fit$df > nsel])==0, 
+                             lambdamax*ifelse(n < p, 0.01, 0.0001),
+                             ifelse(df.fit$df[1] > nsel,
+                                    df.fit$lambda[df.fit$df < nsel][1],
+                                    df.fit$lambda[df.fit$df > nsel][1]))
+         lambda <- exp(seq(log(lambdamax), log(lambdamin), length.out=nlambda))
+         if(length(unique(lambda))==1) {
+           found <- TRUE
+           lambda <- c(max(abs(t(x) %*% (y - mean(y)*(1 - mean(y)))))/(n*seq.alpha[a]),
+                       unique(lambda))
+         }
+         suppressWarnings(df.fit <- glmnet(x, y, family="binomial", alpha=seq.alpha[a], 
+                                           standardize=FALSE, lambda=lambda, 
+                                           intercept=intercept))
+       } else {
+         lambda <- tail(df.fit$lambda[1:tail(which(df.fit$df==nsel), n=1L)], n=2L)
+         if(length(unique(lambda))==1) {
+           lambda <- c(max(abs(t(x) %*% (y - mean(y)*(1 - mean(y)))))/(n*seq.alpha[a]), 
+                       unique(lambda))
+         }
+       }
+     }
+     
+     # cross-validate the lambda and alpha combination
+     cv.fit <- cv.glmnet(x, y, family="binomial", lambda=lambda, alpha=seq.alpha[a], 
+                         standardize=FALSE, intercept=intercept)
+     seq.cvll[a] <- ifelse(type=="ridge", min(cv.fit$cvm), tail(cv.fit$cvm, n=1L))
+     seq.lam[a] <- ifelse(type=="ridge", cv.fit$lambda.min, tail(cv.fit$lambda, n=1L))
+     seq.df[a] <- ifelse(type=="ridge", p, ifelse(!any(df.fit$df==nsel),
+                                                  max(df.fit$df[which.min(abs(df.fit$df - nsel))]),
+                                                  df.fit$df[tail(which(df.fit$df==nsel), n=1L)]))
+   }
+   cvll <- min(seq.cvll)
+   df <- seq.df[which.min(seq.cvll)]
+   
+   lambdaglmnet <- seq.lam[which.min(seq.cvll)]
+   alphaglmnet <- seq.alpha[which.min(seq.cvll)]
+   lambda1pen <- lambdaglmnet*alphaglmnet*n
+   lambda2pen <- lambdaglmnet*(1 - alphaglmnet)*n*0.5
+   lambda1bayes <- lambdaglmnet*alphaglmnet*n*2
+   lambda2bayes <- lambdaglmnet*(1 - alphaglmnet)*n
+   
+   out <- list(lambdaglmnet=lambdaglmnet, alphaglmnet=alphaglmnet, lambda1pen=lambda1pen, 
+               lambda2pen=lambda2pen, lambda1bayes=lambda1bayes, lambda2bayes=lambda2bayes, 
+               cvll=cvll, df=df)
+   return(out)
+ }
> 
> # function to run grVBEM with post hoc variable selection
> grVBEM2sel <- function(x, y, m, partitions, lambda1=NULL, lambda2=NULL, nsel, intercept, 
+                        monotone, posterior, eps, maxiter, trace=TRUE, alphastart) {
+   
+   nparts <- length(partitions)
+   sizes <- lapply(partitions, function(part) {rle(sort(part))$lengths})
+   fit.grVBEM <- grVBEM2(x, y, m, partitions, lambda1, lambda2, intercept, monotone, 
+                         posterior, eps, maxiter, trace, alphastart)
+   lambdagvec <- exp(colSums(log(sapply(1:nparts, function(part) {
+     rep(fit.grVBEM$lambdag[[part]][, fit.grVBEM$nouteriter + 1], times=sizes[[part]])}))))
+   
+   lambda1 <- lambda1/2
+   lambda2 <- lambda2/2
+   fit.grensel <- penalized(y, x, ~1, lambda1*sqrt(lambdagvec), lambda2*lambdagvec, 
+                            model="logistic", trace=FALSE)
+   lambda1min <- 0
+   lambda1max <- max(abs(as.numeric(t(x) %*% (y - 0.5)))/sqrt(lambdagvec))
+   nselcur <- sum(fit.grensel@penalized!=0)
+   
+   while(nselcur!=nsel) {
+     if(nselcur < nsel) {
+       lambda1max <- lambda1
+     } else if(nselcur > nsel) {
+       lambda1min <- lambda1
+     }
+     lambda1 <- (lambda1max + lambda1min)/2
+     fit.grensel <- penalized(y, x, ~1, lambda1*sqrt(lambdagvec), lambda2*lambdagvec, 
+                              model="logistic", trace=FALSE)
+     nselcur <- sum(fit.grensel@penalized!=0)
+   }
+   
+   return(fit.grensel)
+   
+ }
> 
> 
> ### the simulation
> set.seed(2017)
> p <- 500
> G <- 5
> pg <- p/G
> meanbeta <- 0.05
> nblock <- 20
> n <- 100
> rho <- 0.3
> sigma2 <- 1
> m <- rep(1, n)
> q <- 0.9
> f <- 1.7
> groups <- rep(1:G, each=pg)
> partition1 <- list(groups=groups)
> partition2 <- list(groups=CreatePartition(as.factor(groups)))
[1] "Summary of group sizes:"
  1   2   3   4   5 
100 100 100 100 100 
> pblock <- p/nblock
> ubeta <- rep(rev(sapply(0:(G - 1), function(g) {c(f^(-g), 0)})), 
+              times=rep(c(pg*q, pg*(1 - q)), times=G))
> beta <- ubeta*meanbeta/mean(ubeta)
> sigma <- matrix(rho, ncol=pblock, nrow=pblock)
> diag(sigma) <- sigma2
> 
> ntest <- 1000
> nreps <- 50
> nselseq <- c(1, 2, 3, 5, 10, 15, 20, 30)
> 
> aucmat <- kappamat <- precmat <- recmat <- matrix(NA, ncol=4, nrow=nreps*length(nselseq))
> nselmat <- matrix(NA, ncol=4*G, nrow=nreps*length(nselseq))
> 
> for(r in 1:nreps) {
+   
+   # creating the data
+   x <- do.call(cbind, replicate(nblock, rmvnorm(n, mean=rep(0, pblock), sigma=sigma), 
+                                 simplify=FALSE))
+   prob <- as.numeric(exp(x %*% beta)/(1 + exp(x %*% beta)))
+   y <- rbinom(n, m, prob)
+   
+   # creating test data
+   xtest <- do.call(cbind, replicate(nblock, rmvnorm(ntest, mean=rep(0, pblock), 
+                                                     sigma=sigma), simplify=FALSE))
+   probtest <- as.numeric(exp(xtest %*% beta)/(1 + exp(xtest %*% beta)))
+   ytest <- rbinom(ntest, rep(m, ntest), probtest)
+     
+   # different number of selected variables
+   for(cursel in 1:length(nselseq)) {
+     
+     nsel <- nselseq[cursel]
+     
+     print(paste("################### rep ", r, ", nsel ", nsel, " ###################", sep=""))
+     
+     # cross-validating the various penalty parameters
+     penparsen <- cv.pensel(x, y, intercept=TRUE, nsel=nsel, type="enet")
+     penparsridge <- cv.pensel(x, y, intercept=TRUE, nsel=nsel, type="ridge")
+     penparslasso <- cv.pensel(x, y, intercept=TRUE, nsel=nsel, type="lasso")
+     
+     # fitting the different models
+     fit.grridge <- grridge(t(x), y, partition2, selectionEN=TRUE, maxsel=nsel, stepsel=nsel,
+                            optl=penparsridge$lambda2pen, trace=FALSE)
+     fit.lasso <- glmnet(x, y, family="binomial", alpha=1, lambda=penparslasso$lambdaglmnet,
+                         standardize=FALSE)
+     fit.en <- glmnet(x, y, family="binomial", alpha=penparsen$alphaglmnet, 
+                      lambda=penparsen$lambdaglmnet, standardize=FALSE)
+     fit.gren <- grVBEM2sel(x, y, m, partition1, penparsen$lambda1bayes, penparsen$lambda2bayes, 
+                            nsel, TRUE, FALSE, FALSE, 0.001, 1000, FALSE, NULL)
+     
+     # which variables are selected per method
+     sel.grridge <- as.numeric(fit.grridge$resEN$whichEN)
+     sel.lasso <- which(as.numeric(coef(fit.lasso)[-1])!=0)
+     sel.en <- which(as.numeric(coef(fit.en)[-1])!=0)
+     sel.gren <- as.numeric(which(fit.gren@penalized!=0))
+     
+     # refit for predictions
+     fit.grridge2 <- cv.glmnet(cbind(1, x[, sel.grridge]), y, family="binomial", alpha=0, standardize=FALSE)
+     fit.lasso2 <- cv.glmnet(cbind(1, x[, sel.lasso]), y, family="binomial", alpha=0, standardize=FALSE)
+     fit.en2 <- cv.glmnet(cbind(1, x[, sel.en]), y, family="binomial", alpha=0, standardize=FALSE)
+     fit.gren2 <- cv.glmnet(cbind(1, x[, sel.gren]), y, family="binomial", alpha=0, standardize=FALSE)
+     
+     # predict using new data
+     pred.grridge <- as.numeric(predict(fit.grridge2, newx=cbind(1, xtest[, sel.grridge]), s="lambda.min"))
+     pred.lasso <- as.numeric(predict(fit.lasso2, newx=cbind(1, xtest[, sel.lasso]), s="lambda.min"))
+     pred.en <- as.numeric(predict(fit.en2, newx=cbind(1, xtest[, sel.en]), s="lambda.min"))
+     pred.gren <- as.numeric(predict(fit.gren2, newx=cbind(1, xtest[, sel.gren]), s="lambda.min"))
+     
+     # calculating the auc's on the test data
+     auc.grridge <- as.numeric(pROC::roc(ytest, pred.grridge)$auc)
+     auc.lasso <- as.numeric(pROC::roc(ytest, pred.lasso)$auc)
+     auc.en <- as.numeric(pROC::roc(ytest, pred.en)$auc)
+     auc.gren <- as.numeric(pROC::roc(ytest, pred.gren)$auc)
+     
+     # confusion tables
+     tab.grridge <- table(as.numeric(c(1:p) %in% sel.grridge), as.numeric(beta!=0))
+     tab.lasso <- table(as.numeric(c(1:p) %in% sel.lasso), as.numeric(beta!=0))
+     tab.en <- table(as.numeric(c(1:p) %in% sel.en), as.numeric(beta!=0))
+     tab.gren <- table(as.numeric(c(1:p) %in% sel.gren), as.numeric(beta!=0))
+     
+     # calculating the kappa of variable selection
+     kappa.grridge <- cohen.kappa(tab.grridge)$kappa
+     kappa.lasso <- cohen.kappa(tab.lasso)$kappa
+     kappa.en <- cohen.kappa(tab.en)$kappa
+     kappa.gren <- cohen.kappa(tab.gren)$kappa
+     
+     # precisions
+     prec.grridge <- tab.grridge[2, 2]/(tab.grridge[2, 2] + tab.grridge[2, 1])
+     prec.lasso <- tab.lasso[2, 2]/(tab.lasso[2, 2] + tab.lasso[2, 1])
+     prec.en <- tab.en[2, 2]/(tab.en[2, 2] + tab.en[2, 1])
+     prec.gren <- tab.gren[2, 2]/(tab.gren[2, 2] + tab.gren[2, 1])
+     
+     # recalls
+     rec.grridge <- tab.grridge[2, 2]/(tab.grridge[2, 2] + tab.grridge[1, 2])
+     rec.lasso <- tab.lasso[2, 2]/(tab.lasso[2, 2] + tab.lasso[1, 2])
+     rec.en <- tab.en[2, 2]/(tab.en[2, 2] + tab.en[1, 2])
+     rec.gren <- tab.gren[2, 2]/(tab.gren[2, 2] + tab.gren[1, 2])
+     
+     # determining the number of selected variables per group
+     nsel.grridge <- sapply(1:G, function(g) {sum(sel.grridge %in% c(((g - 1)*pg + 1):(g*pg)))})
+     nsel.lasso <- sapply(1:G, function(g) {sum(sel.lasso %in% c(((g - 1)*pg + 1):(g*pg)))})
+     nsel.en <- sapply(1:G, function(g) {sum(sel.en %in% c(((g - 1)*pg + 1):(g*pg)))})
+     nsel.gren <- sapply(1:G, function(g) {sum(sel.gren %in% c(((g - 1)*pg + 1):(g*pg)))})
+     
+     # assigning the metrics to a matrix row
+     aucmat[(cursel - 1)*nreps + r, ] <- c(auc.grridge, auc.lasso, auc.en, auc.gren)
+     kappamat[(cursel - 1)*nreps + r, ]  <- c(kappa.grridge, kappa.lasso, kappa.en, kappa.gren) 
+     precmat[(cursel - 1)*nreps + r, ]  <- c(prec.grridge, prec.lasso, prec.en, prec.gren) 
+     recmat[(cursel - 1)*nreps + r, ]  <- c(rec.grridge, rec.lasso, rec.en, rec.gren) 
+     nselmat[(cursel - 1)*nreps + r, ] <- c(nsel.grridge, nsel.lasso, nsel.en, nsel.gren)
+     
+     # res1 is with q=0.7
+     res2 <- list(auc=aucmat, kappa=kappamat, precision=precmat, recall=recmat, nsel=nselmat)
+     save(res2, file=paste(path.res, "grVBEM_sim5_res2.Rdata", sep=""))
+   }
+   
+ }
Error in x %*% beta : non-conformable arguments
Execution halted
